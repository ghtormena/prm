<!-- ===================================================================== -->
<!--                       README ‚Äì Mission-ROS 2 ü§ñ                         -->
<!-- ===================================================================== -->
# Sistema de Navega√ß√£o & Controle da Miss√£o com ROS 2 ü§ñ

Projeto para o **Trabalho Avaliado 2 ‚Äì Rob√¥s M√≥veis**: um rob√¥ aut√¥nomo que explora o
ambiente, detecta uma bandeira, se posiciona para captur√°-la e a captura, e ent√£o retorna √† posi√ß√£o inicial com a bandeira usando **ROS 2 Humble**.

<p align="center">
  <img src="Images/capturando_bandeira.png" alt="Demonstra√ß√£o da miss√£o completa">
</p>

<div align="center">

[![ROS 2 Humble](https://img.shields.io/badge/ROS%202-Humble-blue.svg)](https://www.ros.org/)
[![Build](https://img.shields.io/badge/build-colcon-brightgreen)](#como-compilar-e-rodar-)
[![License](https://img.shields.io/github/license/Vinicius-GN/Projeto_PRM.svg)](LICENSE)

</div>

---
<div align="center">

‚Ä¢ [Estrutura](#estrutura-do-reposit√≥rio-üìÇ)
‚Ä¢ [Vis√£o Geral](#vis√£o-geral-üó∫Ô∏è)
‚Ä¢ [Estrat√©gia](#estrat√©gia-adotadaüéØ)
‚Ä¢ [Pacotes ROS 2](#pacotes-ros-2-utilizados)
‚Ä¢ [Arquitetura & Algoritmos](#arquitetura--algoritmos-‚öôÔ∏è)
‚Ä¢ [Requisitos Atendidos](#requisitos-atendidos-‚úÖ)
‚Ä¢ [Compilar e Rodar](#como-compilar-e-rodar-üöÄ)
‚Ä¢ [Contribui√ß√£o](#contribui√ß√£o-ü§ù)
‚Ä¢ [Licen√ßa](#licen√ßa-üìÑ)
‚Ä¢ [Membros](#membros-üë•)

</div>

---

## Estrutura do reposit√≥rio üìÇ

```bash
mission-ros2/
‚îú‚îÄ‚îÄ config/
‚îú‚îÄ‚îÄ description/           # Modelo Xacro do rob√¥
‚îú‚îÄ‚îÄ launch/                # Arquivos .launch.py
‚îÇ   ‚îú‚îÄ‚îÄ launch_integrado.launch.py #Arquivo de incicializa√ß√£o da simula√ß√£o e dos pacotes de mapeamento e navega√ß√£o.
‚îú‚îÄ‚îÄ models/
‚îú‚îÄ‚îÄ prm/
‚îÇ   ‚îú‚îÄ‚îÄ mission_manager.py # M√°quina de estados global
‚îÇ   ‚îî‚îÄ‚îÄ flag_servo.py      # Servo-vis√£o/LiDAR, controle da garra
‚îú‚îÄ‚îÄ resource/                # Recursos 3D
‚îú‚îÄ‚îÄ rviz/
‚îú‚îÄ‚îÄ test/
‚îú‚îÄ‚îÄ world/
‚îú‚îÄ‚îÄ images/                
‚îú‚îÄ‚îÄ package.xml            
‚îú‚îÄ‚îÄ setup.py
‚îî‚îÄ‚îÄ README.md
```

---

## Vis√£o geral üó∫Ô∏è

| Componente (pasta/arquivo) | Tipo | Responsabilidade principal | T√≥picos / recursos ROS 2 usados |
|-----------------------------|------|----------------------------|---------------------------------|
| **`prm/mission_manager.py`** | N√≥ Python | M√°quina de estados global (Explorar ‚Üí Encontra Bandeira ‚Üí Flag_servo (aproxima√ß√£o e captura) ‚Üí Retorno √† base). Salva pose inicial, gera metas ao Nav2 para explora√ß√£o do mapa, chama flag_servo ao encontrar a bandeira, escuta `/flag_servo_arrived` para voltar √† base. | `nav2_msgs/action/FollowWaypoints`, `geometry_msgs/PoseStamped`, `tf2_ros`, `/map`, `/odom` |
| **`scripts/flag_servo.py`** | N√≥ Python | C√¢mera Segmentada + LiDAR: alinha, aproxima-se e captura da bandeira, publica conclus√£o. | `/robot_cam/colored_map`, `sensor_msgs/LaserScan`, `/cmd_vel`, `/flag_servo_enable`, `/flag_servo_arrived` |
| **`launch/launch_integrado.launch.py`** | Launch file | Sobe SLAM Toolbox, Nav2 stack, launch `inicializa_simulcao.launch.py` e `carrega_robo.launch.py`. | `ros2 launch` |
| *`description/robot.urdf.xacro`** | Modelo | Rob√¥ diferencial com c√¢mera, LiDAR e IMU; frames TF corretos. | `robot_state_publisher`, `gazebo_ros_pkgs` |

---

## Pacotes ROS 2 utilizados

| Categoria                     | Pacote / ferramenta                                         | Fun√ß√£o na solu√ß√£o                                                                         |
|-------------------------------|-------------------------------------------------------------|-------------------------------------------------------------------------------------------|
| **Localiza√ß√£o & Mapeamento**  | `slam_toolbox`                                              | SLAM s√≠ncrono 2 D; publica `/map` e TF `map ‚Üî odom`                                       |
| **Navega√ß√£o**                 | `nav2_bt_navigator`, `nav2_controller`, `nav2_planner`      | Planejamento global (A*) e controle local (DWB)                                           |
| **Vis√£o**                     | `image_transport`, `cv_bridge`, `sensor_msgs`              | Converte frame da c√¢mera do Gazebo ‚Üí OpenCV para segmentar a bandeira                     |
| **Comunica√ß√£o**               | `rclpy`, `tf2_ros`                                          | N√≥ Python e transforma√ß√µes de quadros                                                    |
| **Simula√ß√£o**                 | `gazebo_ros`, `prm_gazebo`                                  | Carrega o mundo base, sensores de c√¢mera e LiDAR                                          |


---

## Estrat√©gia AdotadaüéØ
### Vis√£o de Alto N√≠vel
```mermaid
stateDiagram-v2
    direction LR
    [*] --> EXPLORANDO : start
    EXPLORANDO --> SERVO : bandeira_vista
    SERVO --> RETORNO : alinhado e caprurado
    RETORNO --> [*] : miss√£o_conclu√≠da

    %% Anota√ß√µes de cada estado
    note right of EXPLORANDO
      Frontier-based exploration
      Nav2 FollowWaypoints
    end note

    note right of SERVO
      Vision + LiDAR leituras
      Controle (v,œâ) proporcional para alinhamento
    end note

    note right of RETORNO
      Goal = home_pose
      Nav2 NavigateToPose
    end note
```


---

## Estrat√©gia detalhada

### 0. Utiliza√ß√£o do SLAM toolbox
Considerando a proposta apresentada pelo trabalho de permitir uma navega√ß√£o universal em ambientes desconhecidos, a ideia inicial foi adotar o uso do SLAM (Simultanious Localization and Mapping), de forma a permitir que houvesse uma representa√ß√£o em ocuppancy grid do ambiente e facilitando a posterior navega√ß√£o do rob√¥ pelo ambiente por meio de algorimos de planejamento de trajet√≥ria. Para isso, foi utilizado o pacote do Slam_ToolBox, que oferece funcionalidades de mapeamento s√≠ncrono/ass√≠ncrono com otimiza√ß√£o em tempo real.

### 1. Explora√ß√£o guiada por fronteiras (`EXPLORANDO`)
Durante esta etapa, o principal objetivo √© explorar o mapa em busca da bandeira, de forma aut√¥noma e baseando-se em algoritmos de planejamento de trajet√≥ria. Para isso, utilizamos uma adapta√ß√£o nossa do algoritmo *Incremental Frontier Exploration* implementado no **`mission_manager.py`**, cuja implementa√ß√£o √© definida abaixo. O resultado √© a explora√ß√£o completa do mapa at√© encontrar a bandeira.

#### L√≥gica:

- A cada atualiza√ß√£o do t√≥pico `/map`, identificam-se as **fronteiras** entre regi√µes mapeadas e n√£o mapeadas.
- Aplica-se um filtro de seguran√ßa que ignora pontos muito pr√≥ximos de obst√°culos.
- As c√©lulas s√£o classificadas da seguinte forma:
  - `-1`: c√©lulas ainda n√£o mapeadas
  - `0`: c√©lulas livres
  - `100`: c√©lulas ocupadas

#### Fluxo do Algoritmo:

1. Detectar pontos de fronteiras entre √°reas conhecidas e desconhecidas.
2. Aplicar filtro de seguran√ßa baseado na dist√¢ncia a obst√°culos.
3. Selecionar o ponto de fronteira **mais distante** do rob√¥, de forma a garantir uma cobertura maior do mapa.
4. Enviar esse ponto ao *action server*: **Nav2 `FollowWaypoints`**


<p align="center">
  <img src="Images/Mapping2.png" alt="Exemplo de rota de explora√ß√£o">
</p>

### 2. Detec√ß√£o robusta da bandeira (BANDEIRA DETECTADA)
Enquanto faz-se a explora√ß√£o e o mapeamento por meio do algoritmo acima descrito, um callback do t√≥pico da c√¢mera de segmenta√ß√£o extrai a imagem e segmenta a regi√£o de interesse no espa√ßo de cores HSV que corresponde √† cor da bandeira **[HSV_MIN = (110, 50, 50) HSV_MAX = (125, 255, 255)]**. O frame chega em BGR, √© convertido para HSV com `cv_bridge` e recebe **threshold**. Ent√£o. uma heur√≠stica de √°rea (> 1750 px) √© aplicada para evitar falsos-positivos oriundos de ru√≠dos, garantindo que a explora√ß√£o pare quando a bandeira for encontrada e estiver suficientemente presente na imagem do rob√¥


<p align="center">
  <img src="Images/bandeira.png" alt="Exemplo de rota de explora√ß√£o" width="600">
</p>

### 3. Aproxima√ß√£o da bandeira (NAVIGANDO_PARA_BANDEIRA E POSICIONANDO_PARA_COLETA)
Esta parte da estrat√©gia √© controlada pelo n√≥ `flag_servo`, que fica aguarando a publica√ß√£o de "true" no t√≥pico "/flag_servo_enable' para iniciar a busca da bandeira. O rob√¥ ent√£o extrai a imagem da bandeira segmentada da mesma forma que na estrat√©gia anterior, calcula o centr√≥ide da bandeira na imagem e faz um controle proporcional para manter o alinhamento com a bandeira, enquanto verifica a dist√¢ncia dos feixes frontais do LIDAR. Ao atingir um bom alinhamento e proximidade suficiente, captura a bandeira.
Resumo do algoritmo:
Enquanto o contorno est√° presente:  
* **œâ** proporcional ao erro do centr√≥ide (pixels).  
* **v** decrescente com a m√©dia dos 90 ¬∞ frontais do LiDAR (*range-keeper*).  
* Quando `|erro| < 10 px` **e** dist√¢ncia `< 0.35 m` ‚Üí Entra num alinhamento final, para garantir que est√° completamente alinhado √† bandeira, e ent√£o a captura.
* publica `/flag_servo_arrived`.

### 4. Retorno √† base  
O primeiro TF `map ‚Üí odom` capturado vira `home_pose` para voltar para a base. Ap√≥s alinhamento, a m√°quina de estados envia esse `PoseStamped` ao **Nav2 NavigateToPose**; ao receber status **`SUCCEEDED`** a miss√£o termina com o rob√¥ j√° na base.


<p align="center">
  <img src="Images/Returning_base.png" alt="Exemplo de rota de explora√ß√£o">
</p>
---

## Arquitetura & algoritmos ‚öôÔ∏è

### 1. Explora√ß√£o por fronteiras
1. Matriz `occ_grid` proveniente do **`slam_toolbox`**.  
2. M√°scara **fronteira** = c√©lula **livre** com vizinho **desconhecido**.  
3. Filtro: dist√¢ncia > 0.2 m de obst√°culos (**distance transform**).  
4. Convers√£o para o frame `map`; remove duplicatas (< 0.5 m).  
5. Seleciona a mais distante ‚áí envia ao action **`FollowWaypoints`**.

### 2. Detec√ß√£o da bandeira (OpenCV)

```python
hsv  = cv.cvtColor(cv_img, cv.COLOR_BGR2HSV)
mask = cv.inRange(hsv, HSV_MIN, HSV_MAX)
cnts, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
```
### 3. Servo-vis√£o + LiDAR (`flag_servo.py`)

| Constante       | Valor      | Fun√ß√£o / Observa√ß√£o                      |
|-----------------|------------|------------------------------------------|
| `v_max`         | **0.20 m/s** | Velocidade linear inicial               |
| `Kp`            | **0.004**    | Ganho proporcional usado em œâ (rad/s)   |
| `stop_distance` | **0.35 m**   | Dist√¢ncia alvo medida pelo LiDAR frontal|
| `dead_zone`     | **¬±10 px**   | Margem de erro aceit√°vel no centr√≥ide   |

Ciclo de controle a cada 100 ms:

1. **Segmenta√ß√£o da bandeira** ‚Äì obt√©m centr√≥ide e √°rea do contorno ciano.  
2. **C√°lculo de erro angular** ‚Äì diferen√ßa horizontal entre centr√≥ide e centro da imagem.  
3. **Controle de rota√ß√£o** ‚Äì œâ proporcional ao erro (ganho `Kp`).  
4. **Controle de avan√ßo** ‚Äì `v` reduz‚Äêse gradualmente conforme a m√©dia dos 90 ¬∞ frontais do LiDAR indica aproxima√ß√£o ao alvo; jamais cai abaixo de 0.06 m/s at√© parar em `stop_distance`.  
5. **Condi√ß√£o de parada** ‚Äì quando `|erro| < 10 px` **e** dist√¢ncia `< 0.35 m`, publica `/flag_servo_arrived`, sinalizando √† m√°quina de estados que o rob√¥ est√° alinhado e posicionado.

### 4. Retorno √† base

* A primeira transforma√ß√£o **`map ‚Üí odom`** recebida √© armazenada como `home_pose`.  
* No estado **RETORNO**, esse `PoseStamped` √© enviado como meta √∫nica ao **Nav2 NavigateToPose**.  
* Ao receber o status **`SUCCEEDED`**, o n√≥ `mission_manager` encerra a miss√£o.

---

## Requisitos Atendidos ‚úÖ

Esta se√ß√£o descreve como os requisitos propostos para o trabalho foram integralmente atendidos ao longo do desenvolvimento do sistema.

### ‚úÖ Navega√ß√£o e Explora√ß√£o do Ambiente
- O rob√¥ √© capaz de navegar autonomamente em ambientes desconhecidos com o uso do **SLAM Toolbox**, construindo um mapa 2D em tempo real.
- A explora√ß√£o do ambiente √© guiada por uma estrat√©gia de **fronteiras** (`Frontier-Based Exploration`) customizada, presente no n√≥ `mission_manager.py`.
- Ao encontrar a bandeira, o rob√¥ retorna com sucesso √† sua posi√ß√£o inicial utilizando `Nav2 NavigateToPose`.

### ‚úÖ Detec√ß√£o e Aproxima√ß√£o da Bandeira
- A bandeira √© detectada por vis√£o computacional com base em segmenta√ß√£o de cor HSV.
- O n√≥ `flag_servo.py` realiza o alinhamento e aproxima√ß√£o da bandeira utilizando:
  - Controle proporcional de rota√ß√£o com base na posi√ß√£o da bandeira na imagem.
  - Controle de avan√ßo baseado nas leituras frontais do **LiDAR**.
- Quando a bandeira est√° centralizada e pr√≥xima, o rob√¥ sinaliza a conclus√£o da etapa de aproxima√ß√£o.
- Assim, posiciona a garra para captura. 



### ‚úÖ Captura da bandeira
- O controle do gripper √© feito tanto em flag_servo.py (para captura) quando em mission_manager.py (para dep√≥sito da bandeira na posi√ß√£o inicial).

<p align="center">
  <img src="Images/capturando_bandeira.png" alt="Capturando a bandeira">
</p>

<p align="center">
  <img src="Images/levantando_bandeira.png" alt="Levantando a bandeira">
</p>

<p align="center">
  <img src="Images/locomovendo_bandeira.png" alt="Locomo√ß√£o retronando √† base e segurando a bandeira">
</p>

<p align="center">
  <img src="Images/chegando_base_com_bandeira.png" alt="Chegando √† base com a bandeira">
</p>

<p align="center">
  <img src="Images/depositando_bandeira.png" alt="Depositando bandeira na posi√ß√£o inicial">
</p>

### ‚úÖ Execu√ß√£o Aut√¥noma da Miss√£o
- Uma **m√°quina de estados** controla todas as etapas da miss√£o:
  1. Explora√ß√£o do ambiente.
  2. Detec√ß√£o da bandeira.
  3. Aproxima√ß√£o com servo-vis√£o.
  4. Captura da bandeira.
  5. Retorno autom√°tico √† base (posi√ß√£o inicial).
- A miss√£o √© completamente aut√¥noma, sem necessidade de interven√ß√£o manual.

---

## üõ†Ô∏è Redu√ß√£o Dimensional do Rob√¥ (Extra)

Como melhoria adicional ao projeto, realizamos uma redu√ß√£o proporcional nas dimens√µes do rob√¥, facilitando sua locomo√ß√£o em passagens estreitas e otimizando a navega√ß√£o:

| Par√¢metro        | Valor Original | Valor Atual |
|------------------|----------------|-------------|
| `base_width`     | 0.31 m         | **0.11 m** |
| `base_length`    | 0.42 m         | **0.12 m**  |
| `wheel_ygap`     | 0.025 m        | **0.0125 m**|
| `wheel_xoff`     | 0.12 m         | **0.06 m**  |
| `caster_xoff`    | 0.14 m         | **0.07 m**  |
| `camera_joint`   | (0.215 0 0.05) | **(0.105 0 0.05)** |

> As demais dimens√µes (altura, rodas, sensores, IMU) foram mantidas para preservar o comportamento f√≠sico e funcional do rob√¥ original.

Al√©m disso, o sistema j√° est√° preparado para **retornar automaticamente √† base** ap√≥s a coleta, utilizando a pose salva no in√≠cio da miss√£o.

---

## Como compilar e rodar üöÄ

```bash
# 1. Clonar
cd ~/ros2_ws/src
git clone https://github.com/Vinicius-GN/prm/

# 2. Compilar
cd ~/ros2_ws
source /opt/ros/humble/setup.bash
rosdep install --from-paths src --ignore-src -r -y
colcon build
source install/setup.sh

# 3. Executar simula√ß√£o
# Terminal A ‚Äî mundo + rob√¥
ros2 launch prm launch_integrado.launch.py

# Terminal D ‚Äî L√≥gica do Servo
source install/setup.sh
ros2 run prm flag_servo

# Terminal C ‚Äî Nav2 + miss√£o
source install/setup.sh
ros2 run prm mission_manager

#Nota: O launch demora por volta de 20 segundos para inicializar todos os pacotes. Dessa forma, aguarde um tempo antes de rodar os n√≥s da miss√£o.
= Ao rodar o script do mission manager, alguns warnings aparecem. Aguarde alguns segundos at√© estabilizar e a explora√ß√£o ser iniciada.
# Qualquer d√∫vida ou erros encontrados, falar com os membros do grupo.

```

---

## Contribui√ß√£o ü§ù

Sugest√µes, *bug-reports* e **pull requests** s√£o muito bem-vindos!  
Abra uma **Issue** para discutir melhorias ou envie o **PR** diretamente.

---

## Membros üë•

| Nome                  | N√∫mero USP | GitHub                                 |
|-----------------------|------------|----------------------------------------|
| Vinicius Gustierrez Neves      | 14749363   | [@Vinicius-GN](https://github.com/Vinicius-GN)|
| Giovanna Herculano Tormena      | 12674335   |[@ghtormena](https://github.com/ghtormena)| |
| Guilheme Rebecchi         | 12550107   | |

