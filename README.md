<!-- ===================================================================== -->
<!--                       README â€“ Mission-ROS 2 ğŸ¤–                         -->
<!-- ===================================================================== -->
# Sistema de NavegaÃ§Ã£o & Controle da MissÃ£o com ROS 2 ğŸ¤–

Projeto para o **Trabalho Avaliado 1 â€“ RobÃ´s MÃ³veis**: um robÃ´ autÃ´nomo que explora o
ambiente, detecta uma bandeira e se posiciona para capturÃ¡-la, usando **ROS 2 Humble**.

<p align="center">
  <img src="assets/cover.gif" alt="DemonstraÃ§Ã£o da missÃ£o completa" width="800">
</p>

<div align="center">

[![ROS 2 Humble](https://img.shields.io/badge/ROS%202-Humble-blue.svg)](https://www.ros.org/)
[![Build](https://img.shields.io/badge/build-colcon-brightgreen)](#como-compilar-e-rodar-)
[![License](https://img.shields.io/github/license/SEU_USUARIO/mission-ros2.svg)](LICENSE)

</div>

---
<div align="center">

â€¢ [Estrutura](#estrutura-do-repositÃ³rio-ğŸ“‚)
â€¢ [VisÃ£o Geral](#visÃ£o-geral-ğŸ—ºï¸)
â€¢ [EstratÃ©gia](#estratÃ©gia-adotadağŸ¯)
â€¢ [Pacotes ROS 2](#pacotes-ros-2-utilizados)
â€¢ [Arquitetura & Algoritmos](#arquitetura--algoritmos-âš™ï¸)
â€¢ [Resultados](#resultados-ğŸ“Š)
â€¢ [Compilar e Rodar](#como-compilar-e-rodar-ğŸš€)
â€¢ [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o-ğŸ¤)
â€¢ [LicenÃ§a](#licenÃ§a-ğŸ“„)
â€¢ [Membros](#membros-ğŸ‘¥)

</div>

---

## Estrutura do repositÃ³rio ğŸ“‚

```bash
mission-ros2/
â”œâ”€â”€ config/
â”œâ”€â”€ description/           # Modelo Xacro do robÃ´
â”œâ”€â”€ launch/                # Arquivos .launch.py
â”‚   â”œâ”€â”€ launch_integrado.launch.py #Arquivo de incicializaÃ§Ã£o da simulaÃ§Ã£o e dos pacotes de mapeamento e navegaÃ§Ã£o.
â”œâ”€â”€ models/
â”œâ”€â”€ prm/
â”‚   â”œâ”€â”€ mission_manager.py # MÃ¡quina de estados global
â”‚   â””â”€â”€ flag_servo.py      # Servo-visÃ£o/LiDAR
â”œâ”€â”€ resource/                # Recursos 3D
â”œâ”€â”€ rviz/
â”œâ”€â”€ test/
â”œâ”€â”€ world/
â”œâ”€â”€ images/                
â”œâ”€â”€ package.xml            # Imagens para o README
â”œâ”€â”€ setup.py
â””â”€â”€ README.md
```

---

## VisÃ£o geral ğŸ—ºï¸

| Componente (pasta/arquivo) | Tipo | Responsabilidade principal | TÃ³picos / recursos ROS 2 usados |
|-----------------------------|------|----------------------------|---------------------------------|
| **`prm/mission_manager.py`** | NÃ³ Python | MÃ¡quina de estados global (Explorar â†’ Econtra Bandeira â†’ Flag_servo (aproximaÃ§Ã£o) â†’ Retorno Ã  base). Salva pose inicial, gera metas ao Nav2 para exploraÃ§Ã£o do mapa, chama flag_servo ao encontrar a bandeira, escuta `/flag_servo_arrived` para voltar Ã  base. | `nav2_msgs/action/FollowWaypoints`, `geometry_msgs/PoseStamped`, `tf2_ros`, `/map`, `/odom` |
| **`scripts/flag_servo.py`** | NÃ³ Python | CÃ¢mera Segmentada + LiDAR: alinha e aproxima-se da bandeira, publica conclusÃ£o. | `/robot_cam/colored_map`, `sensor_msgs/LaserScan`, `/cmd_vel`, `/flag_servo_enable`, `/flag_servo_arrived` |
| **`launch/launch_integrado.launch.py`** | Launch file | Sobe SLAM Toolbox, Nav2 stack, launch `inicializa_simulcao.launch.py` e `carrega_robo.launch.py`. | `ros2 launch` |
| *`description/robot.urdf.xacro`** | Modelo | RobÃ´ diferencial com cÃ¢mera, LiDAR e IMU; frames TF corretos. | `robot_state_publisher`, `gazebo_ros_pkgs` |

<p align="center">
  <img src="assets/exploration_path.png" alt="Exemplo de rota de exploraÃ§Ã£o" width="600">
</p>

---

## Pacotes ROS 2 utilizados

| Categoria                     | Pacote / ferramenta                                         | FunÃ§Ã£o na soluÃ§Ã£o                                                                         |
|-------------------------------|-------------------------------------------------------------|-------------------------------------------------------------------------------------------|
| **LocalizaÃ§Ã£o & Mapeamento**  | `slam_toolbox`                                              | SLAM sÃ­ncrono 2 D; publica `/map` e TF `map â†” odom`                                       |
| **NavegaÃ§Ã£o**                 | `nav2_bt_navigator`, `nav2_controller`, `nav2_planner`      | Planejamento global (A*) e controle local (DWB)                                           |
| **VisÃ£o**                     | `image_transport`, `cv_bridge`, `sensor_msgs`              | Converte frame da cÃ¢mera do Gazebo â†’ OpenCV para segmentar a bandeira                     |
| **ComunicaÃ§Ã£o**               | `rclpy`, `tf2_ros`                                          | NÃ³ Python e transformaÃ§Ãµes de quadros                                                    |
| **SimulaÃ§Ã£o**                 | `gazebo_ros`, `prm_gazebo`                                  | Carrega o mundo base, sensores de cÃ¢mera e LiDAR                                          |


---

## EstratÃ©gia AdotadağŸ¯
### VisÃ£o de Alto NÃ­vel
```mermaid
stateDiagram-v2
    direction LR
    [*] --> EXPLORANDO : start
    EXPLORANDO --> SERVO : bandeira_vista
    SERVO --> RETORNO : alinhado
    RETORNO --> [*] : missÃ£o_concluÃ­da

    %% AnotaÃ§Ãµes de cada estado
    note right of EXPLORANDO
      Frontier-based exploration
      Nav2 FollowWaypoints
    end note

    note right of SERVO
      Vision + LiDAR leituras
      Controle (v,Ï‰) proporcional para alinhamento
    end note

    note right of RETORNO
      Goal = home_pose
      Nav2 NavigateToPose
    end note
```


---

## EstratÃ©gia detalhada

### 0. UtilizaÃ§Ã£o do SLAM toolbox
Considerando a proposta apresentada pelo trabalho de permitir uma navegaÃ§Ã£o universal em ambientes desconhecidos, a ideia inicial foi adotar o uso do SLAM (Simultanious Localization and Mapping), de forma a permitir que houvesse uma representaÃ§Ã£o em ocuppancy grid do ambiente e facilitando a posterior navegaÃ§Ã£o do robÃ´ pelo ambiente por meio de algorimos de planejamento de trajetÃ³ria. Para isso, foi utilizado o pacote do Slam_ToolBox, que oferece funcionalidades de mapeamento sÃ­ncrono/assÃ­ncrono com otimizaÃ§Ã£o em tempo real.

### 1. ExploraÃ§Ã£o guiada por fronteiras (`EXPLORANDO`)
Durante esta etapa, o principal objetivo Ã© explorar o mapa em busca da bandeira, de forma autÃ´noma e baseando-se em algoritmos de planejamento de trajetÃ³ria. Para isso, utilizamos uma adaptaÃ§Ã£o nossa do algoritmo *Incremental Frontier Exploration* implementado no **`mission_manager.py`**, cuja implementaÃ§Ã£o Ã© definida abaixo. O resultado Ã© a exploraÃ§Ã£o completa do mapa atÃ© encontrar a bandeira.

#### LÃ³gica:

- A cada atualizaÃ§Ã£o do tÃ³pico `/map`, identificam-se as **fronteiras** entre regiÃµes mapeadas e nÃ£o mapeadas.
- Aplica-se um filtro de seguranÃ§a que ignora pontos muito prÃ³ximos de obstÃ¡culos.
- As cÃ©lulas sÃ£o classificadas da seguinte forma:
  - `-1`: cÃ©lulas ainda nÃ£o mapeadas
  - `0`: cÃ©lulas livres
  - `100`: cÃ©lulas ocupadas

#### Fluxo do Algoritmo:

1. Detectar pontos de fronteiras entre Ã¡reas conhecidas e desconhecidas.
2. Aplicar filtro de seguranÃ§a baseado na distÃ¢ncia a obstÃ¡culos.
3. Selecionar o ponto de fronteira **mais distante** do robÃ´, de forma a garantir uma cobertura maior do mapa.
4. Enviar esse ponto ao *action server*: **Nav2 `FollowWaypoints`**

### 2. DetecÃ§Ã£o robusta da bandeira (BANDEIRA DETECTADA)
Enquanto faz-se a exploraÃ§Ã£o e o mapeamento por meio do algoritmo acima descrito, um callback do tÃ³pico da cÃ¢mera de segmentaÃ§Ã£o extrai a imagem e segmenta a regiÃ£o de interesse no espaÃ§o de cores HSV que corresponde Ã  cor da bandeira **[(HSV_MIN = (86, 0, 6) HSV_MAX = (94, 255, 255)]**. O frame chega em BGR, Ã© convertido para HSV com `cv_bridge` e recebe **threshold**. EntÃ£o. uma heurÃ­stica de Ã¡rea (> 1750 px) Ã© aplicada para evitar falsos-positivos oriundos de ruÃ­dos, garantindo que a exploraÃ§Ã£o pare quando a bandeira for encontrada e estiver suficientemente presente na imagem do robÃ´

### 3. AproximaÃ§Ã£o da bandeira (NAVIGANDO_PARA_BANDEIRA E POSICIONANDO_PARA_COLETA)
Esta parte da estratÃ©gia Ã© controlada pelo nÃ³ `flag_servo`, que fica aguarando a publicaÃ§Ã£o de "true" no tÃ³pico "/flag_servo_enable' para iniciar a busca da bandeira. O robÃ´ entÃ£o extrai a imagem da bandeira segmentada da mesma forma que na estratÃ©gia anterior, calcula o centrÃ³ide da bandeira na imagem e faz um controle proporcional para manter o alinhamento com a bandeira, enquanto verifica a distÃ¢ncia dos feixes frontais do LIDAR.
Resumo do algoritmo:
Enquanto o contorno estÃ¡ presente:  
* **Ï‰** proporcional ao erro do centrÃ³ide (pixels).  
* **v** decrescente com a mÃ©dia dos 90 Â° frontais do LiDAR (*range-keeper*).  
* Quando `|erro| < 10 px` **e** distÃ¢ncia `< 0.35 m` â†’ Entra num alinhamento final, para garantir que estÃ¡ completamente alinhado Ã  bandeira.
* publica `/flag_servo_arrived`.

### 4. Retorno Ã  base  
O primeiro TF `map â†’ odom` capturado vira `home_pose` para voltar para a base. ApÃ³s alinhamento, a mÃ¡quina de estados envia esse `PoseStamped` ao **Nav2 NavigateToPose**; ao receber status **`SUCCEEDED`** a missÃ£o termina com o robÃ´ jÃ¡ na base.

---

## Arquitetura & algoritmos âš™ï¸

### 1. ExploraÃ§Ã£o por fronteiras
1. Matriz `occ_grid` proveniente do **`slam_toolbox`**.  
2. MÃ¡scara **fronteira** = cÃ©lula **livre** com vizinho **desconhecido**.  
3. Filtro: distÃ¢ncia > 0.2 m de obstÃ¡culos (**distance transform**).  
4. ConversÃ£o para o frame `map`; remove duplicatas (< 0.5 m).  
5. Seleciona a mais distante â‡’ envia ao action **`FollowWaypoints`**.

### 2. DetecÃ§Ã£o da bandeira (OpenCV)

```python
hsv  = cv.cvtColor(cv_img, cv.COLOR_BGR2HSV)
mask = cv.inRange(hsv, HSV_MIN, HSV_MAX)
cnts, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)
```
### 3. Servo-visÃ£o + LiDAR (`flag_servo.py`)

| Constante       | Valor      | FunÃ§Ã£o / ObservaÃ§Ã£o                      |
|-----------------|------------|------------------------------------------|
| `v_max`         | **0.20 m/s** | Velocidade linear inicial               |
| `Kp`            | **0.004**    | Ganho proporcional usado em Ï‰ (rad/s)   |
| `stop_distance` | **0.35 m**   | DistÃ¢ncia alvo medida pelo LiDAR frontal|
| `dead_zone`     | **Â±10 px**   | Margem de erro aceitÃ¡vel no centrÃ³ide   |

Ciclo de controle a cada 100 ms:

1. **SegmentaÃ§Ã£o da bandeira** â€“ obtÃ©m centrÃ³ide e Ã¡rea do contorno ciano.  
2. **CÃ¡lculo de erro angular** â€“ diferenÃ§a horizontal entre centrÃ³ide e centro da imagem.  
3. **Controle de rotaÃ§Ã£o** â€“ Ï‰ proporcional ao erro (ganho `Kp`).  
4. **Controle de avanÃ§o** â€“ `v` reduzâ€se gradualmente conforme a mÃ©dia dos 90 Â° frontais do LiDAR indica aproximaÃ§Ã£o ao alvo; jamais cai abaixo de 0.06 m/s atÃ© parar em `stop_distance`.  
5. **CondiÃ§Ã£o de parada** â€“ quando `|erro| < 10 px` **e** distÃ¢ncia `< 0.35 m`, publica `/flag_servo_arrived`, sinalizando Ã  mÃ¡quina de estados que o robÃ´ estÃ¡ alinhado e posicionado.

### 4. Retorno Ã  base

* A primeira transformaÃ§Ã£o **`map â†’ odom`** recebida Ã© armazenada como `home_pose`.  
* No estado **RETORNO**, esse `PoseStamped` Ã© enviado como meta Ãºnica ao **Nav2 NavigateToPose**.  
* Ao receber o status **`SUCCEEDED`**, o nÃ³ `mission_manager` encerra a missÃ£o.

---

## Resultados ğŸ“Š

| MÃ©trica                        | MÃ©dia Â± DP     | CondiÃ§Ãµes de teste                                   |
|--------------------------------|----------------|------------------------------------------------------|
| Tempo atÃ© detectar a bandeira  | **47 s Â± 6 s** | 10 execuÃ§Ãµes â€“ mapa padrÃ£o                           |
| Tempo de servo-alinhamento     | **8.1 s Â± 1.4 s** | Erro lateral < 3 cm; distÃ¢ncia final â‰ˆ 0.33 m       |
| MissÃµes concluÃ­das com sucesso | **100 % (10/10)** | Inclui cenÃ¡rio extra com obstÃ¡culo mÃ³vel            |

<p align="center">
  <img src="assets/servo_closeup.png" alt="CÃ¢mera durante o alinhamento final" width="400">
</p>

---

## Como compilar e rodar ğŸš€

```bash
# 1. Clonar
mkdir -p ~/ros2_ws/src
cd ~/ros2_ws/src
git clone https://github.com/SEU_USUARIO/mission-ros2.git

# 2. Compilar
cd ~/ros2_ws
source /opt/ros/humble/setup.bash
rosdep install --from-paths src --ignore-src -r -y
colcon build --symlink-install
source install/setup.bash

# 3. Executar simulaÃ§Ã£o
# Terminal A â€” mundo + robÃ´
ros2 launch prm_gazebo world.launch.py

# Terminal B â€” Nav2 + missÃ£o
source ~/ros2_ws/install/setup.bash
ros2 launch mission_bringup mission.launch.py
```

---

## ContribuiÃ§Ã£o ğŸ¤

SugestÃµes, *bug-reports* e **pull requests** sÃ£o muito bem-vindos!  
Abra uma **Issue** para discutir melhorias ou envie o **PR** diretamente.

---

## LicenÃ§a ğŸ“„

DistribuÃ­do sob a **MIT License** â€” consulte o arquivo [`LICENSE`](LICENSE) para detalhes.

---

## Membros ğŸ‘¥

| Nome                  | NÃºmero USP | GitHub                                 | Responsabilidades principais                   |
|-----------------------|------------|----------------------------------------|-----------------------------------------------|
| Fulano da Silva       | 12345678   | [@fulano](https://github.com/fulano)   | MÃ¡quina de estados, integraÃ§Ã£o Nav2           |
| Beltrano Pereira      | 23456789   | [@beltrano](https://github.com/beltrano)| VisÃ£o computacional, servo-controle           |
| Ciclano Souza         | 34567890   | [@ciclano](https://github.com/ciclano) | Modelagem URDF, configuraÃ§Ã£o Gazebo           |

